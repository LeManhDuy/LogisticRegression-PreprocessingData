{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import mean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.preprocessing as pre\n",
    "import sklearn.preprocessing as pre\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from scipy.stats import loguniform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 kĩ thuật xử lý dữ liệu trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị trung vị\n",
    "def median():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    median=data['Age'].median()\n",
    "    data['Age']=data['Age'].fillna(median)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị trung bình\n",
    "def mean():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    mean = data['Age'].mean()\n",
    "    data['Age']=data['Age'].fillna(mean)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị xuất hiện nhiều nhất\n",
    "def mode():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    mode = data['Age'].mode()[0]\n",
    "    data['Age']=data['Age'].fillna(mode)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị được lấy ngẫu nhiên\n",
    "def randomsample():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    random_samples = data['Age'].dropna().sample(n=data['Age'].isnull().sum(),random_state=0)\n",
    "    # gan lai index cho series ngau nhien vua tao\n",
    "    random_samples.index = data[data['Age'].isnull()].index\n",
    "    data['Age'].update(random_samples)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tạo đặc trưng mới\n",
    "def new_feature():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    data['Age_NAN']=np.where(data['Age'].isnull(),1,0)\n",
    "    data['Age'].fillna(data.Age.median(),inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị bất kỳ\n",
    "def arbitrary_value():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    data['Age']=data['Age'].fillna(100)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Giá trị tại đuôi của phân bố dữ liệu\n",
    "def end_of_dist():\n",
    "    data  = pd.read_csv('titanic.csv')[['Survived', 'Age', 'Fare','Sex']]\n",
    "    data['Sex']=np.where(data['Sex']=='male',1,0)\n",
    "    # gia tri o duoi cua phan bo (bien Age theo phan bo chuan)\n",
    "    extreme = data['Age'].mean() + 3*data['Age'].std()\n",
    "    data[\"Age\"]=data['Age'].fillna(extreme)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Không xử lý ngoại lệ và có xử lý ngoại lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_outliers(data):\n",
    "    return logistic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(data):\n",
    "    #Dữ liệu dạng phân bố chuẩn\n",
    "    upper_boundary=data['Age'].mean() + 3* data['Age'].std()\n",
    "    lower_boundary=data['Age'].mean() - 3* data['Age'].std()\n",
    "    \n",
    "    #update các giá trị, nếu lớn hơn upper_boundary thì sẽ bằng giá trị upper_boundary\n",
    "    data.loc[data['Age'] >= round(upper_boundary), 'Age'] = round(upper_boundary)\n",
    "\n",
    "    #Dữ liệu dạng phân bố lệch\n",
    "    #q3 tương ứng 75, q1 tương ứng 25\n",
    "    q3 , q1 = np.percentile(data['Fare'], [75,25])\n",
    "    IQR = q3 - q1\n",
    "    upper_bridge = q3 + 3 * IQR\n",
    "    lower_bridge = q1 - 3 * IQR\n",
    "\n",
    "    #update các giá trị, nếu lớn hơn upper_bridge thì sẽ bằng giá trị upper_bridge\n",
    "    data.loc[data['Fare'] >= upper_bridge, 'Fare'] = round(upper_bridge)\n",
    "\n",
    "    return logistic(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(data):\n",
    "    accuracy_arr = []\n",
    "    for i in range(10):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(data[['Age','Fare','Sex']],data['Survived'],test_size=0.3, random_state=i)\n",
    "        classifier=LogisticRegression()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_pred=classifier.predict(X_test)\n",
    "        accuracy_arr.append(accuracy_score(y_test,y_pred))\n",
    "    return np.mean(accuracy_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lựa chọn và đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_hyperparameters_model(data):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(data[['Age','Fare','Sex']],data['Survived'],test_size=0.3, random_state=0)\n",
    "    model = LogisticRegression()\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    solver = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    penalty = ['none', 'l1', 'l2', 'elasticnet']\n",
    "    C = loguniform(1e-5, 100)\n",
    "    space = dict(solver=solver,penalty=penalty,C=C)\n",
    "\n",
    "    search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "    result = search.fit(X_train, y_train)\n",
    "\n",
    "    return result.best_score_,result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.7832650622973202\n",
      "Best parameters:  {'C': 1.0513352083086982, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "best_score, best_params_ = selection_hyperparameters_model(arbitrary_value())\n",
    "print(\"Best score: \", best_score)\n",
    "print(\"Best parameters: \", best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đánh giá độ chính xác mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá độ chính xác của mô hình:  0.7852278545826935\n"
     ]
    }
   ],
   "source": [
    "def rating_model(data, model):\n",
    "    accuracy_test_score_arr = []\n",
    "    for i in range(10):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(data[['Age','Fare','Sex']],data['Survived'],test_size=0.3, random_state=i)\n",
    "        model.fit(X_train,y_train)\n",
    "        result = cross_validate(model, X_train, y_train, scoring=\"accuracy\" ,cv = 10)\n",
    "        accuracy_test_score_arr.append(result['test_score'])\n",
    "    return np.mean(accuracy_test_score_arr)\n",
    "\n",
    "print(\"Đánh giá độ chính xác của mô hình: \", rating_model(arbitrary_value(), LogisticRegression(C = round(best_params_['C']), penalty= best_params_['penalty'], solver= best_params_['solver'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xử lý riêng cho phương pháp new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_outliers_for_new_feature(data):\n",
    "    return logistic_for_new_feature(data)\n",
    "\n",
    "def outlierss_for_new_feature(data):\n",
    "    #Dữ liệu dạng phân bố chuẩn\n",
    "    upper_boundary=data['Age'].mean() + 3* data['Age'].std()\n",
    "    lower_boundary=data['Age'].mean() - 3* data['Age'].std()\n",
    "    \n",
    "    #update các giá trị, nếu lớn hơn upper_boundary thì sẽ bằng giá trị upper_boundary\n",
    "    data.loc[data['Age'] >= round(upper_boundary), 'Age'] = round(upper_boundary)\n",
    "\n",
    "    #Dữ liệu dạng phân bố lệch\n",
    "    #q3 tương ứng 75, q1 tương ứng 25\n",
    "    q3 , q1 = np.percentile(data['Fare'], [75,25])\n",
    "    IQR = q3 - q1\n",
    "    upper_bridge = q3 + 3 * IQR\n",
    "    lower_bridge = q1 - 3 * IQR\n",
    "\n",
    "    #update các giá trị, nếu lớn hơn upper_bridge thì sẽ bằng giá trị upper_bridge\n",
    "    data.loc[data['Fare'] >= upper_bridge, 'Fare'] = round(upper_bridge)\n",
    "\n",
    "    return logistic_for_new_feature(data)\n",
    "    \n",
    "def logistic_for_new_feature(data):\n",
    "    accuracy_arr = []\n",
    "    for i in range(10):\n",
    "        X_train,X_test,y_train,y_test=train_test_split(data[['Age','Age_NAN','Fare','Sex']],data['Survived'],test_size=0.3, random_state=i)\n",
    "        classifier=LogisticRegression()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_pred=classifier.predict(X_test)\n",
    "        accuracy_arr.append(accuracy_score(y_test,y_pred))\n",
    "    return np.mean(accuracy_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = {\n",
    "        'Kỹ thuật xử lý dữ liệu trống': ['Mean', 'Median', 'Mode', 'Random', 'End of Distribution', 'Arbitrary Value', 'New Feature'],\n",
    "        \n",
    "        'Không xử lý ngoại lệ': \n",
    "        [\n",
    "        no_outliers(mean()), \n",
    "        no_outliers(median()), \n",
    "        no_outliers(mode()), \n",
    "        no_outliers(randomsample()), \n",
    "        no_outliers(end_of_dist()), \n",
    "        no_outliers(arbitrary_value()), \n",
    "        no_outliers_for_new_feature(new_feature())\n",
    "        ],\n",
    "\n",
    "        'Có xử lý ngoại lệ':  \n",
    "        [\n",
    "        outliers(mean()), \n",
    "        outliers(median()), \n",
    "        outliers(mode()), \n",
    "        outliers(randomsample()), \n",
    "        outliers(end_of_dist()), \n",
    "        outliers(arbitrary_value()), \n",
    "        outlierss_for_new_feature(new_feature())\n",
    "        ]}\n",
    "statistics = pd.DataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Báo cáo độ chính xác của 14 thuật toán trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bảng báo cáo độ chính xác của thuật toán trong 14 trường hợp\n",
      "\n",
      "   Kỹ thuật xử lý dữ liệu trống  Không xử lý ngoại lệ  Có xử lý ngoại lệ\n",
      "0                         Mean              0.779104           0.780597\n",
      "1                       Median              0.778731           0.780224\n",
      "2                         Mode              0.778731           0.779851\n",
      "3                       Random              0.778358           0.780970\n",
      "4          End of Distribution              0.779104           0.781343\n",
      "5              Arbitrary Value              0.778731           0.779851\n",
      "6                  New Feature              0.779104           0.780597\n"
     ]
    }
   ],
   "source": [
    "#Xuất ra 14 trường hợp\n",
    "print(\"Bảng báo cáo độ chính xác của thuật toán trong 14 trường hợp\\n\\n\",statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KHÔNG XỬ LÝ NGOẠI LỆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Kỹ thuật xử lý dữ liệu trống        Mean\n",
      "Không xử lý ngoại lệ            0.779104\n",
      "Name: 0, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "Kỹ thuật xử lý dữ liệu trống      Random\n",
      "Không xử lý ngoại lệ            0.778358\n",
      "Name: 3, dtype: object\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lớn nhất \n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(statistics.loc[statistics['Không xử lý ngoại lệ']\n",
    ".idxmax()][['Kỹ thuật xử lý dữ liệu trống', 'Không xử lý ngoại lệ']])\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "#Nhỏ nhất\n",
    "print(statistics.loc[statistics['Không xử lý ngoại lệ']\n",
    ".idxmin()][['Kỹ thuật xử lý dữ liệu trống', 'Không xử lý ngoại lệ']])\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CÓ XỬ LÝ NGOẠI LỆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "Kỹ thuật xử lý dữ liệu trống    End of Distribution\n",
      "Có xử lý ngoại lệ                          0.781343\n",
      "Name: 4, dtype: object\n",
      "--------------------------------------------------------------------------\n",
      "Kỹ thuật xử lý dữ liệu trống     Random\n",
      "Có xử lý ngoại lệ               0.78097\n",
      "Name: 3, dtype: object\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lớn nhất \n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(statistics.loc[statistics['Có xử lý ngoại lệ']\n",
    ".idxmax()][['Kỹ thuật xử lý dữ liệu trống', 'Có xử lý ngoại lệ']])\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "#Nhỏ nhất\n",
    "print(statistics.loc[statistics['Không xử lý ngoại lệ']\n",
    ".idxmin()][['Kỹ thuật xử lý dữ liệu trống', 'Có xử lý ngoại lệ']])\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đề xuất các kỹ thuật chuẩn hoá dữ liệu phù hợp để cải thiện độ chính xác của thuật toán hồi quy logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kĩ thuật chuẩn hoá Robust Scaler: \n",
      "\n",
      "Độ chính xác thuật toán không áp dụng kĩ thuật chuẩn hoá :  0.7798507462686566\n",
      "\n",
      "Độ chính xác thuật toán áp dụng kĩ thuật chuẩn hoá :  0.7805970149253731\n",
      "\n",
      "Phần trăm khác biệt giữa 2 thuật toán :  0.075 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Kĩ thuật chuẩn hoá Robust Scaler: \\n\")\n",
    "\n",
    "#chưa qua xử lý\n",
    "accuracy_non_process = outliers(arbitrary_value())\n",
    "print(\"Độ chính xác thuật toán không áp dụng kĩ thuật chuẩn hoá : \", accuracy_non_process)\n",
    "\n",
    "#đã qua xử lý\n",
    "arbitrary_value_copy = arbitrary_value()\n",
    "arbitrary_value_copy = pd.DataFrame(pre.RobustScaler().fit_transform(arbitrary_value_copy), columns=arbitrary_value_copy.columns)\n",
    "accuracy_process = outliers(arbitrary_value_copy)\n",
    "print(\"\\nĐộ chính xác thuật toán áp dụng kĩ thuật chuẩn hoá : \", accuracy_process)\n",
    "\n",
    "#phân trăm khác biệt giữa 2 thuật toán\n",
    "diffirent_percentage = round((accuracy_process - accuracy_non_process)*100,3)\n",
    "print(\"\\nPhần trăm khác biệt giữa 2 thuật toán : \", diffirent_percentage,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kĩ thuật chuẩn hoá Min Max Scaler: \n",
      "\n",
      "Độ chính xác thuật toán không áp dụng kĩ thuật chuẩn hoá :  0.7798507462686566\n",
      "\n",
      "Độ chính xác thuật toán áp dụng kĩ thuật chuẩn hoá :  0.780223880597015\n",
      "\n",
      "Phần trăm khác biệt giữa 2 thuật toán :  0.037 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Kĩ thuật chuẩn hoá Min Max Scaler: \\n\")\n",
    "\n",
    "#chưa qua xử lý\n",
    "accuracy_non_process = outliers(arbitrary_value())\n",
    "print(\"Độ chính xác thuật toán không áp dụng kĩ thuật chuẩn hoá : \", accuracy_non_process)\n",
    "\n",
    "#đã qua xử lý\n",
    "arbitrary_value_copy = arbitrary_value()\n",
    "arbitrary_value_copy = pd.DataFrame(pre.MinMaxScaler().fit_transform(arbitrary_value_copy), columns=arbitrary_value_copy.columns)\n",
    "accuracy_process = outliers(arbitrary_value_copy)\n",
    "print(\"\\nĐộ chính xác thuật toán áp dụng kĩ thuật chuẩn hoá : \", accuracy_process)\n",
    "\n",
    "#phân trăm khác biệt giữa 2 thuật toán\n",
    "diffirent_percentage = round((accuracy_process - accuracy_non_process)*100,3)\n",
    "print(\"\\nPhần trăm khác biệt giữa 2 thuật toán : \", diffirent_percentage,\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2f6f809b2ed56d9097a93784c969695d7a5df466e601ed2b3cda10a2111aad4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
